{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using built-in_Kmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:6: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:6: SyntaxWarning: invalid escape sequence '\\l'\n",
      "C:\\Users\\Talal_HP\\AppData\\Local\\Temp\\ipykernel_29440\\155565899.py:5: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  original_image = cv2.imread('Q1 Dataset\\lady.png')\n",
      "C:\\Users\\Talal_HP\\AppData\\Local\\Temp\\ipykernel_29440\\155565899.py:6: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  aux_image = cv2.imread('Q1 Dataset\\lady stroke 1.png')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation with colored foreground and black background saved to Lady-segmentation.png\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "original_image = cv2.imread('Q1 Dataset\\lady.png')\n",
    "aux_image = cv2.imread('Q1 Dataset\\lady stroke 1.png')\n",
    "\n",
    "# Convert auxiliary image to HSV color space for more reliable color detection\n",
    "aux_hsv = cv2.cvtColor(aux_image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Adaptive thresholding for red and blue colors\n",
    "red_lower = np.array([0, 100, 50])\n",
    "red_upper = np.array([10, 255, 255])\n",
    "blue_lower = np.array([100, 100, 50])\n",
    "blue_upper = np.array([130, 255, 255])\n",
    "\n",
    "# Create masks for red and blue\n",
    "foreground_mask = cv2.inRange(aux_hsv, red_lower, red_upper)\n",
    "background_mask = cv2.inRange(aux_hsv, blue_lower, blue_upper)\n",
    "\n",
    "# Morphological operations for mask refinement\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "foreground_mask = cv2.morphologyEx(foreground_mask, cv2.MORPH_CLOSE, kernel)\n",
    "background_mask = cv2.morphologyEx(background_mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "# Use masks to extract seed pixels from the original image\n",
    "foreground_pixels = original_image[foreground_mask == 255]\n",
    "background_pixels = original_image[background_mask == 255]\n",
    "\n",
    "# Check if any seeds are detected\n",
    "if foreground_pixels.size == 0 or background_pixels.size == 0:\n",
    "    raise ValueError(\"No seeds detected. Please check the color thresholds and auxiliary image.\")\n",
    "\n",
    "# K-Means clustering on the foreground and background seed pixels\n",
    "kmeans_fg = KMeans(n_clusters=8, random_state=42).fit(foreground_pixels)\n",
    "kmeans_bg = KMeans(n_clusters=8, random_state=42).fit(background_pixels)\n",
    "\n",
    "def compute_likelihood(pixel, kmeans):\n",
    "    return np.min(np.linalg.norm(pixel - kmeans.cluster_centers_, axis=1))\n",
    "\n",
    "height, width, _ = original_image.shape\n",
    "segmentation_mask = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "for i in range(height):\n",
    "    for j in range(width):\n",
    "        likelihood_fg = compute_likelihood(original_image[i, j], kmeans_fg)\n",
    "        likelihood_bg = compute_likelihood(original_image[i, j], kmeans_bg)\n",
    "        segmentation_mask[i, j] = 255 if likelihood_fg < likelihood_bg else 0\n",
    "\n",
    "# Refine segmentation mask\n",
    "segmentation_mask = cv2.morphologyEx(segmentation_mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "# Apply segmentation mask to original image\n",
    "foreground_color = cv2.bitwise_and(original_image, original_image, mask=segmentation_mask)\n",
    "\n",
    "background_black = np.zeros_like(original_image)\n",
    "\n",
    "# Use the segmentation mask to isolate the background in the black image\n",
    "# No need to invert the mask since we're directly using the foreground mask\n",
    "background = cv2.bitwise_and(background_black, background_black, mask=cv2.bitwise_not(segmentation_mask))\n",
    "\n",
    "# Combine the color foreground with the black background\n",
    "combined_image = cv2.add(foreground_color, background)\n",
    "\n",
    "# Save the colored foreground with black background image\n",
    "output_colored_path = 'Lady-segmentation.png'\n",
    "cv2.imwrite(output_colored_path, combined_image)\n",
    "\n",
    "print(f\"Segmentation with colored foreground and black background saved to {output_colored_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Custom Kmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation with colored foreground and black background saved to Lady-segmentation.png\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def kmeans(data, k, n_iterations=100):\n",
    "    np.random.seed(42)\n",
    "    indices = np.random.choice(len(data), k, replace=False)\n",
    "    centers = data[indices]\n",
    "    \n",
    "    for _ in range(n_iterations):\n",
    "        distances = np.sqrt(((data - centers[:, np.newaxis])**2).sum(axis=2))\n",
    "        closest_cluster = np.argmin(distances, axis=0)\n",
    "        new_centers = np.array([data[closest_cluster == j].mean(axis=0) for j in range(k)])\n",
    "        \n",
    "        if np.all(centers == new_centers):\n",
    "            break\n",
    "        centers = new_centers\n",
    "    \n",
    "    return centers\n",
    "\n",
    "def compute_likelihood(pixel, centers):\n",
    "    return np.min(np.linalg.norm(pixel - centers, axis=1))\n",
    "\n",
    "def generate_masks_from_strokes(stroke_image_paths):\n",
    "    aggregated_foreground_mask = None\n",
    "    aggregated_background_mask = None\n",
    "\n",
    "    for path in stroke_image_paths:\n",
    "        aux_image = cv2.imread(path)\n",
    "        aux_hsv = cv2.cvtColor(aux_image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        foreground_mask = cv2.inRange(aux_hsv, red_lower, red_upper)\n",
    "        background_mask = cv2.inRange(aux_hsv, blue_lower, blue_upper)\n",
    "\n",
    "        kernel = np.ones((5, 5), np.uint8)\n",
    "        foreground_mask = cv2.morphologyEx(foreground_mask, cv2.MORPH_CLOSE, kernel)\n",
    "        background_mask = cv2.morphologyEx(background_mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "        if aggregated_foreground_mask is None:\n",
    "            aggregated_foreground_mask = foreground_mask\n",
    "        else:\n",
    "            aggregated_foreground_mask = cv2.bitwise_or(aggregated_foreground_mask, foreground_mask)\n",
    "\n",
    "        if aggregated_background_mask is None:\n",
    "            aggregated_background_mask = background_mask\n",
    "        else:\n",
    "            aggregated_background_mask = cv2.bitwise_or(aggregated_background_mask, background_mask)\n",
    "\n",
    "    return aggregated_foreground_mask, aggregated_background_mask\n",
    "\n",
    "original_image = cv2.imread('Q1 Dataset/lady.png')\n",
    "\n",
    "# List of paths to your stroke images\n",
    "stroke_image_paths = ['Q1 Dataset/lady stroke 1.png', 'Q1 Dataset/lady stroke 2.png']  # Add your paths here\n",
    "\n",
    "red_lower = np.array([0, 100, 50])\n",
    "red_upper = np.array([10, 255, 255])\n",
    "blue_lower = np.array([100, 100, 50])\n",
    "blue_upper = np.array([130, 255, 255])\n",
    "\n",
    "foreground_mask, background_mask = generate_masks_from_strokes(stroke_image_paths)\n",
    "\n",
    "foreground_pixels = original_image[foreground_mask == 255]\n",
    "background_pixels = original_image[background_mask == 255]\n",
    "\n",
    "if foreground_pixels.size == 0 or background_pixels.size == 0:\n",
    "    raise ValueError(\"No seeds detected. Please check the color thresholds and auxiliary image.\")\n",
    "\n",
    "centers_fg = kmeans(foreground_pixels.reshape(-1, 3), 3)\n",
    "centers_bg = kmeans(background_pixels.reshape(-1, 3), 3)\n",
    "\n",
    "height, width, _ = original_image.shape\n",
    "segmentation_mask = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "for i in range(height):\n",
    "    for j in range(width):\n",
    "        likelihood_fg = compute_likelihood(original_image[i, j], centers_fg)\n",
    "        likelihood_bg = compute_likelihood(original_image[i, j], centers_bg)\n",
    "        segmentation_mask[i, j] = 255 if likelihood_fg < likelihood_bg else 0\n",
    "\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "segmentation_mask = cv2.morphologyEx(segmentation_mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "foreground_color = cv2.bitwise_and(original_image, original_image, mask=segmentation_mask)\n",
    "background_black = np.zeros_like(original_image)\n",
    "background = cv2.bitwise_and(background_black, background_black, mask=cv2.bitwise_not(segmentation_mask))\n",
    "combined_image = cv2.add(foreground_color, background)\n",
    "\n",
    "output_colored_path = 'Lady-segmentation.png'\n",
    "cv2.imwrite(output_colored_path, combined_image)\n",
    "\n",
    "print(f\"Segmentation with colored foreground and black background saved to {output_colored_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
